{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# dataset\n",
   "id": "1e8cbf9a969abb35"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-04T00:04:48.712141Z",
     "start_time": "2026-02-04T00:04:48.702547Z"
    }
   },
   "source": [
    "import json\n",
    "data_path=\"/root/dataset/skin/SkinCAP/SkinCAP_20250712_121252_close_end_QA.json\"\n",
    "with open(data_path,encoding='utf-8') as file:\n",
    "    data=json.load(file)\n",
    "\n",
    "print(data[0])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_name': '10.png', 'caption_zh': '红色光滑的外生性结节，根部稍缩窄。考虑鳞癌待查', 'caption_zh_polish': '红色光滑的外生性结节，根部稍缩窄，可能是鳞癌的表现。鳞癌是一种常见的皮肤肿瘤，通常起源于表皮层的角化细胞。这种类型的肿瘤通常会表现为皮肤上的病变，如结节或溃疡，需要进行进一步检查以确认诊断。', 'caption_zh_polish_en': 'The red, smooth, exophytic nodule with a slightly narrowed base may indicate squamous cell carcinoma. Squamous cell carcinoma is a common type of skin tumor that typically originates from the keratinocytes in the epidermis. This type of tumor often presents as skin lesions such as nodules or ulcers, and further investigation is needed to confirm the diagnosis.', 'answer': 'squamous cell carcinoma', 'question_type': 'close_end_QA'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Parse the response message",
   "id": "396a0b0f844ed9df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T00:21:25.146296Z",
     "start_time": "2026-02-04T00:15:54.220851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import datasets\n",
    "\n",
    "BASE_IMG_DIR = \"/root/dataset/skin/SkinCAP/skincap\"\n",
    "\n",
    "ds = datasets.Dataset.from_list(data)\n",
    "\n",
    "def add_image_path(ex):\n",
    "    ex[\"image_path\"] = os.path.join(BASE_IMG_DIR, ex[\"image_name\"])\n",
    "    return ex\n",
    "\n",
    "ds = ds.map(add_image_path)\n",
    "\n",
    "# Make it an Image column (this is fine)\n",
    "ds = ds.cast_column(\"image_path\", datasets.Image())\n",
    "\n",
    "SYSTEM = \"SYSTEM INSTRUCTION: think silently if needed.\"\n",
    "USER_TEMPLATE = (\n",
    "    \"You are given a clinical image and a question.\\n\"\n",
    "    \"Return ONLY the disease name in English. No extra words.\\n\"\n",
    "    \"Question: {q}\\n\"\n",
    ")\n",
    "\n",
    "def to_prompt(ex):\n",
    "    q = ex.get(\"caption_zh_polish_en\") or ex.get(\"caption_zh\") or \"\"\n",
    "    return {\n",
    "        # prompt ONLY text (fully serializable)\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": USER_TEMPLATE.format(q=q)},\n",
    "        ],\n",
    "        \"answer\": ex[\"answer\"],\n",
    "        # keep image in its own column\n",
    "        \"image\": ex[\"image_path\"],\n",
    "    }\n",
    "\n",
    "# Important: remove image_path if you create image column,\n",
    "# otherwise you keep both (either is ok, but be consistent)\n",
    "ds = ds.map(to_prompt)\n",
    "\n",
    "# keep only what you need\n",
    "keep_cols = [\"prompt\", \"answer\", \"image\", \"image_name\", \"question_type\"]\n",
    "ds = ds.remove_columns([c for c in ds.column_names if c not in keep_cols])\n"
   ],
   "id": "6685f49b419897d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1631 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33a64c60dcbb4475954ba207a6500316"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1631 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "429bdaf66b52419c83de7162868461c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T00:24:06.134763Z",
     "start_time": "2026-02-04T00:24:06.130276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def _get_completion_text(completion) -> str:\n",
    "    # conversational: [[{\"role\":\"assistant\",\"content\":\"...\"}]]\n",
    "    if isinstance(completion, list) and completion and isinstance(completion[0], dict):\n",
    "        return completion[0].get(\"content\", \"\") or \"\"\n",
    "    # non-conversational: \"...\"\n",
    "    return str(completion) if completion is not None else \"\"\n",
    "\n",
    "def _normalize_disease(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    # drop wrappers like quotes\n",
    "    s = s.strip('\"').strip(\"'\")\n",
    "    # remove common prefixes\n",
    "    s = re.sub(r\"^\\s*(final\\s*answer\\s*:\\s*)\", \"\", s)\n",
    "    # keep letters/numbers/spaces\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# 你可以按你的任务继续扩充\n",
    "_ALIAS = {\n",
    "    \"scc\": \"squamous cell carcinoma\",\n",
    "    \"squamous cell ca\": \"squamous cell carcinoma\",\n",
    "    \"squamous cell cancer\": \"squamous cell carcinoma\",\n",
    "    \"bcc\": \"basal cell carcinoma\",\n",
    "    \"basal cell cancer\": \"basal cell carcinoma\",\n",
    "    \"mm\": \"melanoma\",\n",
    "}\n",
    "\n",
    "def _canonicalize(s: str) -> str:\n",
    "    s = _normalize_disease(s)\n",
    "    return _normalize_disease(_ALIAS.get(s, s))\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    rewards = []\n",
    "    for comp, gt in zip(completions, answer):\n",
    "        pred_raw = _get_completion_text(comp)\n",
    "        pred = _canonicalize(pred_raw)\n",
    "        gt_norm = _canonicalize(str(gt))\n",
    "\n",
    "        if not pred:\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # strict match\n",
    "        if pred == gt_norm:\n",
    "            rewards.append(1.0)\n",
    "            continue\n",
    "\n",
    "        # optional: allow substring match (model outputs extra words)\n",
    "        # If you really want ONLY disease name, keep this as 0.0 (strict).\n",
    "        if gt_norm in pred or pred in gt_norm:\n",
    "            rewards.append(0.5)\n",
    "            continue\n",
    "\n",
    "        # optional: fuzzy fallback (protects against minor typos)\n",
    "        sim = SequenceMatcher(None, pred, gt_norm).ratio()\n",
    "        rewards.append(0.5 if sim >= 0.92 else 0.0)\n",
    "\n",
    "    return rewards\n"
   ],
   "id": "c21c946ab3d3a92f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GRPO config",
   "id": "d2958ecc8c8cb423"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2026-02-04T00:24:59.457648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from peft import LoraConfig\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "ckpt = \"/root/model/medgemma-1.5-4b-it\"\n",
    "output_dir=\"/root/model/GRPO_medgemma4b\"\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    eval_on_start=False,                     # Run an evaluation at the very beginning of training.\n",
    "    learning_rate=5e-6,                      # The initial learning rate for the AdamW optimizer.\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,           # Accumulate gradients for this many steps to simulate a larger batch size (per_device_train_batch_size * gradient_accumulation_steps).\n",
    "    num_generations=2,                       # Number of completions to generate per prompt for GRPO's preference learning.\n",
    "    max_prompt_length=512,                   # Maximum token length for input prompts.\n",
    "    max_completion_length=1024,              # Maximum token length for the model's generated completions.\n",
    "    max_steps=1700,\n",
    "    logging_steps=20,\n",
    "    save_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    report_to=\"tensorboard\",\n",
    "    use_vllm=True,                           # Use the vLLM library for significantly faster inference during generation.\n",
    "    vllm_mode=\"colocate\",                    # vLLM deployment mode; 'colocate' runs vLLM on the same GPU(s) as the trainer.\n",
    "    vllm_gpu_memory_utilization=.30,         # Fraction of GPU memory that vLLM is allowed to use.\n",
    "    bf16=True,                               # Enable bfloat16 mixed precision training to save memory and speed up training.\n",
    "    gradient_checkpointing=True,             # Save memory by trading compute (avoids storing all intermediate activations).\n",
    "    gradient_checkpointing_kwargs={\n",
    "        \"use_reentrant\": False               # Use a more efficient implementation of gradient checkpointing.\n",
    "    },\n",
    "    model_init_kwargs={\n",
    "        \"device_map\": \"auto\",\n",
    "        \"dtype\": torch.bfloat16,             # Set model parameter data type to bfloat16.\n",
    "        \"attn_implementation\": \"eager\"       # Gemma 3 recommends using the 'eager' attention implementation.\n",
    "    },\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=64,\n",
    "    lora_alpha=64,\n",
    "    target_modules=\"all-linear\",\n",
    ")"
   ],
   "id": "2e7bca2a0873656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# train model",
   "id": "924595726b4065f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = ds.select(range(0, 3900))\n",
    "eval_dataset  = ds.select(range(3900, 4000))\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=ckpt,\n",
    "    reward_funcs=[correctness_reward_func],\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=lora_config,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir=training_args.output_dir)"
   ],
   "id": "4549b12b99e12f10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-08T18:21:38.969978Z",
     "start_time": "2026-02-08T18:21:38.948899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "p = \"dataset/skin/SkinCAP/SkinCAP_20260208_173640_close_end_QA.json\"\n",
    "data = json.load(open(p, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "bad = 0\n",
    "for i, ex in enumerate(data):\n",
    "    for k in [\"answer\", \"image_name\", \"question_type\", \"caption_zh_polish_en\"]:\n",
    "        v = ex.get(k, None)\n",
    "        if v is not None and not isinstance(v, str):\n",
    "            print(\"BAD\", i, k, type(v), v)\n",
    "            bad += 1\n",
    "            break\n",
    "\n",
    "print(\"bad_count=\", bad)"
   ],
   "id": "9fb78528e82b474b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_count= 0\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
